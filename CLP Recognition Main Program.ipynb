{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "              'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '川', '鄂', '赣', '甘', '贵',\n",
    "              '桂', '黑', '沪', '冀', '津', '京', '吉', '辽', '鲁', '蒙', '闽', '宁', '青', '琼', '陕', '苏', '晋',\n",
    "              '皖', '湘', '新', '豫', '渝', '粤', '云', '藏', '浙']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funciton are usd to remove the small area of the image. the tiny scale would be delete.\n",
    "def vscale(rotate_rect):\n",
    "   threthold = 0.4\n",
    "   aspect = 4#4.7272\n",
    "   MIN = 10*(10*aspect)\n",
    "   MAX = 150*(150*aspect)\n",
    "   min_aspect = aspect*(1-threthold)\n",
    "   max_aspect = aspect*(1+threthold)\n",
    "   theta = 30\n",
    "   if rotate_rect[1][0]==0 or rotate_rect[1][1]==0:\n",
    "       return False\n",
    "   r = rotate_rect[1][0]/rotate_rect[1][1]\n",
    "   r = max(r,1/r)\n",
    "   area = rotate_rect[1][0]*rotate_rect[1][1]\n",
    "   if area>MIN and area<MAX and r>min_aspect and r<max_aspect:\n",
    "         # the angle of the rectangular can not over 4/pi\n",
    "       if ((rotate_rect[1][0] < rotate_rect[1][1] and rotate_rect[2] >= -90 and rotate_rect[2] < -(90 - theta)) or\n",
    "               (rotate_rect[1][1] < rotate_rect[1][0] and rotate_rect[2] > -theta and rotate_rect[2] <= 0)):\n",
    "           return True\n",
    "   return False\n",
    "\n",
    "# To adjust the angle of image or the character angle of the image to avoid the image was shooting by strange angle\n",
    "# If the image was shooting in strange angle, license plate would not parallel to the edge of the image\n",
    "# And the character would have different size, shape or height compare with normal condition.\n",
    "# So this function is used to transform the license plate part looks like normal condition\n",
    "def image_Transform(car, img):\n",
    "    return_flag = False\n",
    "    has_throeed = True\n",
    "    height,weidth = img.shape[:2]\n",
    "    wedith_react,heigth_react = car[1][0], car[1][1]\n",
    "    angle = car[2]\n",
    "    if car[2]==0:\n",
    "        return_flag = True\n",
    "        has_throeed = False\n",
    "    if car[2]==-90 and wedith_react<heigth_react:\n",
    "        wedith_react, heigth_react = heigth_react, wedith_react\n",
    "        return_flag = True\n",
    "        has_throeed = False\n",
    "    if return_flag:\n",
    "        car_img = img[int(car[0][1] - heigth_react / 2):int(car[0][1] + heigth_react / 2),\n",
    "                  int(car[0][0] - wedith_react / 2):int(car[0][0] + wedith_react / 2)]\n",
    "        return car_img\n",
    "    car = (car[0], (wedith_react, heigth_react), angle)\n",
    "    box = cv2.boxPoints(car)\n",
    "    height_p = right_point = [0,0]\n",
    "    left_p = low_point = [car[0][0], car[0][1]]\n",
    "    for p in box:\n",
    "        if left_p[0] > p[0]:\n",
    "            left_p = p\n",
    "        if low_point[1] > p[1]:\n",
    "            low_point = p\n",
    "        if height_p[1] < p[1]:\n",
    "            height_p = p\n",
    "        if right_point[0] < p[0]:\n",
    "            right_point = p\n",
    "    if left_p[1] <= right_point[1]:\n",
    "        new_right_point = [right_point[0], height_p[1]]\n",
    "        pts1 = np.float32([left_p, height_p, right_point])\n",
    "        pts2 = np.float32([left_p, height_p, new_right_point])\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        dst = cv2.warpAffine(img, M, (round(weidth * 2), round(height * 2)))\n",
    "        car_img = dst[int(left_p[1]):int(height_p[1]), int(left_p[0]):int(new_right_point[0])]\n",
    "    elif left_p[1] > right_point[1]:\n",
    "        new_left_point = [left_p[0], height_p[1]]\n",
    "        pts1 = np.float32([left_p, height_p, right_point])\n",
    "        pts2 = np.float32([new_left_point, height_p, right_point])\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        dst = cv2.warpAffine(img, M, (round(weidth * 2), round(height * 2)))\n",
    "        car_img = dst[int(right_point[1]):int(height_p[1]), int(new_left_point[0]):int(right_point[0])]\n",
    "\n",
    "    return car_img\n",
    "\n",
    "\n",
    "# Some times CV2.imshow would cause error.\n",
    "def preprocessing(orig):\n",
    "    gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.blur(gray, (3, 3))\n",
    "    sobel = cv2.Sobel(blur, cv2.CV_16S, 1, 0, ksize=3)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "    hsv = cv2.cvtColor(orig, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = hsv[:, :, 0], hsv[:, :, 1], hsv[:, :, 2]\n",
    "    # Yellow between[26,34] blue[100,124]\n",
    "    # Our project default in blue.\n",
    "    blue = (((h > 26) & (h < 34)) | ((h > 100) & (h < 124))) & (s > 70) & (v > 70)\n",
    "    blue = blue.astype('float32')\n",
    "    mix = np.multiply(sobel, blue)\n",
    "    mix = mix.astype(np.uint8)\n",
    "    ret, binary = cv2.threshold(mix, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    kk = cv2.getStructuringElement(cv2.MORPH_RECT,(21,5))\n",
    "    close = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kk)\n",
    "    return close\n",
    "\n",
    "# verify it was reel lincense palte by flood fill algorithm.\n",
    "def verify_color(rotate_rect,src_image):\n",
    "    height,wedith = src_image.shape[:2]\n",
    "    mask_point = np.zeros(shape=[height+2,wedith+2],dtype=np.uint8)\n",
    "    kernal2 = np.ones((5, 27), np.float64)\n",
    "    kernel = np.ones((5, 23), np.uint8)\n",
    "    connectivity = 4\n",
    "    lower,upper = 30,30\n",
    "    new_value = 255\n",
    "    flags = connectivity\n",
    "    flags |= cv2.FLOODFILL_FIXED_RANGE  # consider the different betweeen seed and pixel\n",
    "    flags |= new_value << 8\n",
    "    flags |= cv2.FLOODFILL_MASK_ONLY #mask the part of image that not the lincens plate.\n",
    "    rand_seed_num = 5000 #generate random seed.\n",
    "    valid_seed_num = 200 #Select 200 vaild seed\n",
    "    newp = 0.1\n",
    "    points_select = cv2.boxPoints(rotate_rect)\n",
    "    points_x = [n[0] for n in points_select]\n",
    "    points_x.sort(reverse=False)\n",
    "    adjust_x = int((points_x[2]-points_x[1])*newp)\n",
    "    range_col = [points_x[1]+adjust_x,points_x[2]-adjust_x]\n",
    "    points_y = [n[1] for n in points_select]\n",
    "    points_y.sort(reverse=False)\n",
    "    new_y = int((points_y[2]-points_y[1])*newp)\n",
    "    row_range = [points_y[1]+new_y, points_y[2]-new_y]\n",
    "    if (range_col[1]-range_col[0])/(points_x[3]-points_x[0])<0.4\\\n",
    "        or (row_range[1]-row_range[0])/(points_y[3]-points_y[0])<0.4:\n",
    "        row_of_points = []\n",
    "        col_of_points = []\n",
    "        for i in range(2):\n",
    "            pt1,pt2 = points_select[i],points_select[i+2]\n",
    "            x_adjust,y_adjust = int(newp*(abs(pt1[0]-pt2[0]))),int(newp*(abs(pt1[1]-pt2[1])))\n",
    "            if (pt1[0] <= pt2[0]):\n",
    "                pt1[0], pt2[0] = pt1[0] + x_adjust, pt2[0] - x_adjust\n",
    "            else:\n",
    "                pt1[0], pt2[0] = pt1[0] - x_adjust, pt2[0] + x_adjust\n",
    "            if (pt1[1] <= pt2[1]):\n",
    "                pt1[1], pt2[1] = pt1[1] + new_y, pt2[1] - new_y\n",
    "            else:\n",
    "                pt1[1], pt2[1] = pt1[1] - y_adjust, pt2[1] + y_adjust\n",
    "            x_list = [int(x) for x in np.linspace(pt1[0],pt2[0],int(rand_seed_num /2))]\n",
    "            list_y = [int(y) for y in np.linspace(pt1[1],pt2[1],int(rand_seed_num /2))]\n",
    "            col_of_points.extend(x_list)\n",
    "            row_of_points.extend(list_y)\n",
    "    else:\n",
    "        row_of_points = np.random.randint(row_range[0],row_range[1],size=rand_seed_num)\n",
    "        col_of_points = np.linspace(range_col[0],range_col[1],num=rand_seed_num).astype(np.int)\n",
    "    row_of_points = np.array(row_of_points)\n",
    "    col_of_points = np.array(col_of_points)\n",
    "    hsv_img = cv2.cvtColor(src_image, cv2.COLOR_BGR2HSV)\n",
    "    h,s,v = hsv_img[:,:,0],hsv_img[:,:,1],hsv_img[:,:,2]\n",
    "    # use the floodfill to fill the image.\n",
    "    flood_img = src_image.copy()\n",
    "    seed_cnt = 0\n",
    "    for i in range(rand_seed_num):\n",
    "        rand_index = np.random.choice(rand_seed_num,1,replace=False)\n",
    "        row,col = row_of_points[rand_index],col_of_points[rand_index]\n",
    "        # To limit the background color of the seed.\n",
    "        if (((h[row,col]>26)&(h[row,col]<34))|((h[row,col]>100)&(h[row,col]<124)))&(s[row,col]>70)&(v[row,col]>70):\n",
    "            cv2.floodFill(src_image, mask_point, (int(col),int(row)), (255, 255, 255), (lower,) * 3, (upper,) * 3, flags)\n",
    "            cv2.circle(flood_img,center=(int(col),int(row)),radius=2,color=(0,0,255),thickness=2)\n",
    "            seed_cnt += 1\n",
    "            if seed_cnt >= valid_seed_num:\n",
    "                break\n",
    "    # print the image after floodfill algorithm\n",
    "    show_seed = np.random.uniform(1,100,1).astype(np.uint16)\n",
    "    #cv2.imshow('floodfill'+str(show_seed),flood_img)\n",
    "    #cv2.imshow('flood_mask'+str(show_seed),mask_point)\n",
    "    newpoints_mask = []\n",
    "    for row in range(1,height+1):\n",
    "        for col in range(1,wedith+1):\n",
    "            if mask_point[row,col] != 0:\n",
    "                newpoints_mask.append((col-1,row-1))\n",
    "    rotated = cv2.minAreaRect(np.array(newpoints_mask))\n",
    "    if vscale(rotated):\n",
    "        return True,rotated\n",
    "    else:\n",
    "        return False,rotated\n",
    "\n",
    "# split the license plate out for a single picture\n",
    "def carPlateLocation(orig,pred):\n",
    "    carPlate_list = []\n",
    "    temp1_orig = orig.copy() \n",
    "    temp2_orig = orig.copy() \n",
    "    contours,heriachy = cv2.findContours(pred,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for i,contour in enumerate(contours):\n",
    "        cv2.drawContours(temp1_orig, contours, i, (0, 255, 255), 2)\n",
    "        # get the smallest in circle rectangle，return the value of rotate_rect\n",
    "        rotate = cv2.minAreaRect(contour)\n",
    "        # based on rectanle area and lenght ratio to find there is a license plate or not\n",
    "        if vscale(rotate):\n",
    "            ret,rotate2 = verify_color(rotate,temp2_orig)\n",
    "            if ret == False:\n",
    "                continue\n",
    "            # License plate position correction\n",
    "            car_plate = image_Transform(rotate2, temp2_orig)\n",
    "            car_plate = cv2.resize(car_plate,(plate_width,plate_height)) #resize the car plate for CNN input to use\n",
    "            box = cv2.boxPoints(rotate2)\n",
    "            for k in range(4):\n",
    "                n1,n2 = k%4,(k+1)%4\n",
    "                cv2.line(temp1_orig,(box[n1][0],box[n1][1]),(box[n2][0],box[n2][1]),(255,0,0),2)\n",
    "            #cv2.imshow('opencv_' + str(i), car_plate)\n",
    "            carPlate_list.append(car_plate)\n",
    "\n",
    "    #cv2.imshow('contour', temp1_orig_img)\n",
    "    return carPlate_list\n",
    "\n",
    "# cut the character out\n",
    "def split_character(plate):\n",
    "    char_addr_list = []\n",
    "    area_left,rightarea,leftCharacter,char_right= 0,0,0,0\n",
    "    weidith1 = plate.shape[1]\n",
    "    def getColSum(img,col):\n",
    "        sum = 0\n",
    "        for i in range(img.shape[0]):\n",
    "            sum += round(img[i,col]/255)\n",
    "        return sum;\n",
    "    sum = 0\n",
    "    for col in range(weidith1):\n",
    "        sum += getColSum(plate,col)\n",
    "    limit_col = 0 #round(0.5*sum/img_w)\n",
    "    # limit the ratio of height and width of the license plate.\n",
    "    charWid_limit = [round(weidith1/12),round(weidith1/5)]\n",
    "    is_char_flag = False\n",
    "    # To Canny the lincense plate\n",
    "    for i in range(weidith1):\n",
    "        Value_col = getColSum(plate,i)\n",
    "        if Value_col > limit_col:\n",
    "            if is_char_flag == False:\n",
    "                rightarea = round((i+char_right)/2)\n",
    "                area_width = rightarea-area_left\n",
    "                char_width = char_right-leftCharacter\n",
    "                if (area_width>charWid_limit[0]) and (area_width<charWid_limit[1]):\n",
    "                    char_addr_list.append((area_left,rightarea,char_width))\n",
    "                leftCharacter = i\n",
    "                area_left = round((leftCharacter+char_right) / 2)\n",
    "                is_char_flag = True\n",
    "        else:\n",
    "            if is_char_flag == True:\n",
    "                char_right = i-1\n",
    "                is_char_flag = False\n",
    "    if rightarea < leftCharacter:\n",
    "        rightarea,char_right = weidith1,weidith1\n",
    "        area_width = rightarea - area_left\n",
    "        char_width = char_right - leftCharacter\n",
    "        if (area_width > charWid_limit[0]) and (area_width < charWid_limit[1]):\n",
    "            char_addr_list.append((area_left, rightarea, char_width))\n",
    "    return char_addr_list\n",
    "\n",
    "\n",
    "# use the distance between white area to split each area then spilt the character out.\n",
    "def character_split(car_plate):\n",
    "    heigth,weigth = car_plate.shape[:2]\n",
    "    h_proj_list = []\n",
    "    h_temp_len,v_temp_len = 0,0\n",
    "    h_startIndex,h_end_index = 0,0\n",
    "    h_proj_limit = [0.2,0.8]\n",
    "    char_imgs = []\n",
    "    h_count = [0 for i in range(heigth)]\n",
    "    for row in range(heigth):\n",
    "        temp_cnt = 0\n",
    "        for col in range(weigth):\n",
    "            if car_plate[row,col] == 255:\n",
    "                temp_cnt += 1\n",
    "        h_count[row] = temp_cnt\n",
    "        if temp_cnt/weigth<h_proj_limit[0] or temp_cnt/weigth>h_proj_limit[1]:\n",
    "            if h_temp_len != 0:\n",
    "                h_end_index = row-1\n",
    "                h_proj_list.append((h_startIndex,h_end_index))\n",
    "                h_temp_len = 0\n",
    "            continue\n",
    "        if temp_cnt > 0:\n",
    "            if h_temp_len == 0:\n",
    "                h_startIndex = row\n",
    "                h_temp_len = 1\n",
    "            else:\n",
    "                h_temp_len += 1\n",
    "        else:\n",
    "            if h_temp_len > 0:\n",
    "                h_end_index = row-1\n",
    "                h_proj_list.append((h_startIndex,h_end_index))\n",
    "                h_temp_len = 0\n",
    "    if h_temp_len != 0:\n",
    "        h_end_index = heigth-1\n",
    "        h_proj_list.append((h_startIndex, h_end_index))\n",
    "    h_maxIndex,h_maxHeight = 0,0\n",
    "    for i,(start,end) in enumerate(h_proj_list):\n",
    "        if h_maxHeight < (end-start):\n",
    "            h_maxHeight = (end-start)\n",
    "            h_maxIndex = i\n",
    "    if h_maxHeight/heigth < 0.5:\n",
    "        return char_imgs\n",
    "    chars_top,chars_bottom = h_proj_list[h_maxIndex][0],h_proj_list[h_maxIndex][1]\n",
    "    plates = car_plate[chars_top:chars_bottom+1,:]\n",
    "    cv2.imwrite('./Dataset/opencv/car.jpg',car_plate)\n",
    "    cv2.imwrite('./Dataset/opencv/plate.jpg', plates)\n",
    "    char_addr_list = split_character(plates)\n",
    "    for i,addr in enumerate(char_addr_list):\n",
    "        char_img = car_plate[chars_top:chars_bottom+1,addr[0]:addr[1]]\n",
    "        char_img = cv2.resize(char_img,(char_width,char_height))\n",
    "        char_imgs.append(char_img)\n",
    "    return char_imgs\n",
    "\n",
    "# Separate the character out\n",
    "def extract_char(car_plate):\n",
    "    gray_plate = cv2.cvtColor(car_plate,cv2.COLOR_BGR2GRAY)\n",
    "    ret,binary_plate = cv2.threshold(gray_plate,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "    char_img_list = character_split(binary_plate)\n",
    "    return char_img_list\n",
    "\n",
    "# use the trained CNN license plate recognition model to check there is a license plate or not\n",
    "def cnncarPlate(plate_list,paths):\n",
    "    if len(plate_list) == 0:\n",
    "        return False,plate_list\n",
    "    graphh = tf.Graph()\n",
    "    session1 = tf.Session(graph=graphh)\n",
    "    with session1.as_default():\n",
    "        with session1.graph.as_default():\n",
    "            model_pos = os.path.dirname(paths)\n",
    "            savers = tf.train.import_meta_graph(paths)\n",
    "            savers.restore(session1, tf.train.latest_checkpoint(model_pos))\n",
    "            graph = tf.get_default_graph()\n",
    "            net1_x_position = graph.get_tensor_by_name('x_place:0')\n",
    "            net1_keep_position = graph.get_tensor_by_name('keep_place:0')\n",
    "            net1_output = graph.get_tensor_by_name('out_put:0')\n",
    "\n",
    "            input_x = np.array(plate_list)\n",
    "            net_out = tf.nn.softmax(net1_output)\n",
    "            pred = tf.argmax(net_out,1) #predit the results\n",
    "            prob = tf.reduce_max(net_out,reduction_indices=[1]) #result prob\n",
    "            pred_list,prob_list = session1.run([pred,prob],feed_dict={net1_x_position:input_x,net1_keep_position:1.0})\n",
    "            # choose the highest prob license plate\n",
    "            result_index,result_prob = -1,0.\n",
    "            for i,pred in enumerate(pred_list):\n",
    "                if pred==1 and prob_list[i]>result_prob:\n",
    "                    result_index,result_prob = i,prob_list[i]\n",
    "            # boolen variable will use to main program for check the license plate exist or not\n",
    "            if result_index == -1:\n",
    "                return False,plate_list[0]\n",
    "            else:\n",
    "                return True,plate_list[result_index]\n",
    "            \n",
    "# use the trained CNN character recognition model to recognize characters numbers, characters, chinese character\n",
    "# in the table\n",
    "def cnnchar(img_list,paths):\n",
    "    graphhh = tf.Graph()\n",
    "    session2 = tf.Session(graph=graphhh)\n",
    "    text_lists = []\n",
    "\n",
    "    if len(img_list) == 0:\n",
    "        return text_lists\n",
    "    with session2.as_default():\n",
    "        with session2.graph.as_default():\n",
    "            model_pos = os.path.dirname(paths)\n",
    "            savers = tf.train.import_meta_graph(paths)\n",
    "            savers.restore(session2, tf.train.latest_checkpoint(model_pos))\n",
    "            graph = tf.get_default_graph()\n",
    "            net2_x_position = graph.get_tensor_by_name('x_place:0')\n",
    "            net2_keep_position = graph.get_tensor_by_name('keep_place:0')\n",
    "            net2_output = graph.get_tensor_by_name('out_put:0')\n",
    "\n",
    "            data = np.array(img_list)\n",
    "            # numbers, characters, chinese character，total 67 characters\n",
    "            # find the highest prob. results from the table match labels\n",
    "            net_outs = tf.nn.softmax(net2_output)\n",
    "            pred = tf.argmax(net_outs,1)\n",
    "            my_pred= session2.run(pred, feed_dict={net2_x_position: data, net2_keep_position: 1.0})\n",
    "\n",
    "            for i in my_pred:\n",
    "                text_lists.append(character[i])\n",
    "            return text_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/evan/MS/Ece697/bishe /1/./Dataset/models/plate/model.ckpt-510\n",
      "INFO:tensorflow:Restoring parameters from /Users/evan/MS/Ece697/bishe /1/./Dataset/models/char/model.ckpt-510\n",
      "['浙', 'A', 'L', 'P', '5', '2', '0']\n"
     ]
    }
   ],
   "source": [
    "cur_pos = sys.path[0]\n",
    "plate_width,plate_height = 136,36\n",
    "char_width,char_height = 20,20\n",
    "plate_model = os.path.join(cur_pos, './Dataset/models/plate/model.ckpt-510.meta')\n",
    "char_model = os.path.join(cur_pos,'./Dataset/models/char/model.ckpt-510.meta')\n",
    "img = cv2.imread('./Dataset/test_images/1.jpg')\n",
    "\n",
    "#preprocessing\n",
    "pred_img = preprocessing(img)\n",
    "\n",
    "# car plate location\n",
    "plate_list = carPlateLocation(img,pred_img)\n",
    "\n",
    "# CNN car plate recognition\n",
    "bools,car_plate = cnncarPlate(plate_list,plate_model)\n",
    "8\n",
    "if bools == False:\n",
    "    print(\"No License Plates Check Your Image, Try Again\")\n",
    "    sys.exit(-1)\n",
    "#cv2.imshow('cnn_plate',car_plate)\n",
    "\n",
    "# character extract\n",
    "char_image_list = extract_char(car_plate)\n",
    "\n",
    "# CNN Character Recognition\n",
    "char_text = cnnchar(char_image_list,char_model)\n",
    "print(char_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
