{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (made in a same class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plate_recognition_cnn_net:\n",
    "    def __init__(self):\n",
    "        self.img_width,self.img_height = 136,36\n",
    "        self.batch_size = 100\n",
    "        self.learn_rate = 0.001\n",
    "        self.y_size = 2\n",
    "    \n",
    "        self.x_place = tf.placeholder(dtype=tf.float32, shape=[None, self.img_height, self.img_width, 3], name='x_place')\n",
    "        self.y_place = tf.placeholder(dtype=tf.float32, shape=[None, self.y_size], name='y_place')\n",
    "        self.keep_place = tf.placeholder(dtype=tf.float32, name='keep_place')\n",
    "\n",
    "    #The cnn architecture we used for this model training\n",
    "    def cnn_architecture(self):\n",
    "        #input layer - color input 3 channels\n",
    "        x_inputs = tf.reshape(self.x_place, shape=[-1, self.img_height, self.img_width, 3])\n",
    "        \n",
    "        #convelutional layer 1\n",
    "        conv_weight1 = tf.Variable(tf.random_normal(shape=[3, 3, 3, 32], stddev=0.01), dtype=tf.float32)\n",
    "        conv_bias1 = tf.Variable(tf.random_normal(shape=[32]), dtype=tf.float32)\n",
    "        conv_layer1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x_inputs,filter=conv_weight1,strides=[1,1,1,1],padding='SAME'),conv_bias1))\n",
    "        conv_layer1 = tf.nn.max_pool(conv_layer1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv_layer1 = tf.nn.dropout(conv_layer1, self.keep_place)\n",
    "      \n",
    "        #convelutional layer 2\n",
    "        conv_weight2 = tf.Variable(tf.random_normal(shape=[3, 3, 32, 64], stddev=0.01), dtype=tf.float32)\n",
    "        conv_bias2 = tf.Variable(tf.random_normal(shape=[64]), dtype=tf.float32)\n",
    "        conv_layer2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv_layer1,filter=conv_weight2,strides=[1,1,1,1],padding='SAME'),conv_bias2))\n",
    "        conv_layer2 = tf.nn.max_pool(conv_layer2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv_layer2 = tf.nn.dropout(conv_layer2, self.keep_place)\n",
    "\n",
    "        #convelutional layer 3\n",
    "        conv_weight3 = tf.Variable(tf.random_normal(shape=[3, 3, 64, 128], stddev=0.01), dtype=tf.float32)\n",
    "        conv_bias3 = tf.Variable(tf.random_normal(shape=[128]), dtype=tf.float32)\n",
    "        conv_layer3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv_layer2,filter=conv_weight3,strides=[1,1,1,1],padding='SAME'),conv_bias3))\n",
    "        conv_layer3 = tf.nn.max_pool(conv_layer3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv_layer3 = tf.nn.dropout(conv_layer3, self.keep_place)\n",
    "\n",
    "        #full convelutional layer\n",
    "        conv_layer_out = tf.reshape(conv_layer3, shape=[-1, 17 * 5 * 128])\n",
    "\n",
    "        #fully connected layer 1\n",
    "        fully_con_weight1 = tf.Variable(tf.random_normal(shape=[17 * 5 * 128, 1024], stddev=0.01), dtype=tf.float32)\n",
    "        fully_con_bias1 = tf.Variable(tf.random_normal(shape=[1024]), dtype=tf.float32)\n",
    "        fully_con_layer1 = tf.nn.relu(tf.add(tf.matmul(conv_layer_out, fully_con_weight1), fully_con_bias1))\n",
    "        fully_con_layer1 = tf.nn.dropout(fully_con_layer1, self.keep_place)\n",
    "       \n",
    "        #fully connected layer 2\n",
    "        fully_con_weight2 = tf.Variable(tf.random_normal(shape=[1024, 1024], stddev=0.01), dtype=tf.float32)\n",
    "        fully_con_bias2 = tf.Variable(tf.random_normal(shape=[1024]), dtype=tf.float32)\n",
    "        fully_con_layer2 = tf.nn.relu(tf.add(tf.matmul(fully_con_layer1, fully_con_weight2), fully_con_bias2))\n",
    "        fully_con_layer2 = tf.nn.dropout(fully_con_layer2, self.keep_place)\n",
    "\n",
    "        #fully connected layer 3, output layer\n",
    "        fully_con_weight3 = tf.Variable(tf.random_normal(shape=[1024, self.y_size], stddev=0.01), dtype=tf.float32)\n",
    "        fully_con_bias3 = tf.Variable(tf.random_normal(shape=[self.y_size]), dtype=tf.float32)\n",
    "        fully_con_layer3 = tf.add(tf.matmul(fully_con_layer2, fully_con_weight3), fully_con_bias3, name='out_put')\n",
    "\n",
    "        #output the last layer, output shape is class numbers\n",
    "        return fully_con_layer3\n",
    "\n",
    "    #initial data and labels x,y as two np.array\n",
    "    def init_data(self,dir):\n",
    "        X = []\n",
    "        y = []\n",
    "        #check the path exists or not\n",
    "        if not os.path.exists(dir):\n",
    "            raise ValueError('No such file folder')\n",
    "        files = list(paths.list_images(dir))\n",
    "        labels = [file.split(os.path.sep)[-2] for file in files]\n",
    "\n",
    "        for i, file in enumerate(files):\n",
    "            src_img = cv2.imread(file)\n",
    "            if src_img.ndim != 3:\n",
    "                continue\n",
    "            #resize the image as target size\n",
    "            resize_img = cv2.resize(src_img, (136, 36))\n",
    "            X.append(resize_img)\n",
    "            #only two labels, use one hot code\n",
    "            y.append([[0, 1] if labels[i] == 'has' else [1, 0]])\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1, 2)\n",
    "        return X, y\n",
    "\n",
    "    def train(self,data_dir,model_save_path):\n",
    "        #process and read x, y data and labels use the function\n",
    "        X, y = self.init_data(data_dir)\n",
    "        print('loaded' + str(len(y)) + 'dataset')\n",
    "        \n",
    "        #split data as train and validation data set for 8 to 2 ratio\n",
    "        train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        #read the architecture\n",
    "        out_puts = self.cnn_architecture()\n",
    "        predict = tf.nn.softmax(out_puts)\n",
    "        predict = tf.argmax(predict, axis=1)\n",
    "        actual_y = tf.argmax(self.y_place, axis=1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, actual_y), dtype=tf.float32))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_puts, labels=self.y_place))\n",
    "        #optimizer and learning rate\n",
    "        opt = tf.train.AdamOptimizer(self.learn_rate)\n",
    "        train_step = opt.minimize(cost)\n",
    "        \n",
    "        #start the train session\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "            step = 0\n",
    "            saver = tf.train.Saver()\n",
    "            while True:\n",
    "                train_index = np.random.choice(len(train_x), self.batch_size, replace=False)\n",
    "                train_randx = train_x[train_index]\n",
    "                train_randy = train_y[train_index]\n",
    "                _, loss = sess.run([train_step, cost], feed_dict={self.x_place: train_randx,\n",
    "                                                                  self.y_place: train_randy, self.keep_place: 0.75})\n",
    "                step += 1\n",
    "                print(step, loss)\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    test_index = np.random.choice(len(test_x), self.batch_size, replace=False)\n",
    "                    test_randx = test_x[test_index]\n",
    "                    test_randy = test_y[test_index]\n",
    "                    acc = sess.run(accuracy, feed_dict={self.x_place: test_randx,\n",
    "                                                        self.y_place: test_randy, self.keep_place: 1.0})\n",
    "                    print('accuracy:' + str(acc))\n",
    "                    # stop train both step >500 and accuracy > 99%\n",
    "                    if acc > 0.99 and step > 500:\n",
    "                        #save model\n",
    "                        saver.save(sess, model_save_path, global_step=step)\n",
    "                        break\n",
    "\n",
    "    #initial data x as one np.array\n",
    "    def init_testData(self,dir):\n",
    "        test_X = []\n",
    "        #check the path exists or not\n",
    "        if not os.path.exists(dir):\n",
    "            raise ValueError('No such file folder')\n",
    "        files = list(paths.list_images(dir))\n",
    "        for file in files:\n",
    "            src_img = cv2.imread(file, cv2.COLOR_BGR2GRAY)\n",
    "            if src_img.ndim != 3:\n",
    "                continue\n",
    "            resize_img = cv2.resize(src_img, (136, 36))\n",
    "            test_X.append(resize_img)\n",
    "        test_X = np.array(test_X)\n",
    "        return test_X\n",
    "    \n",
    "    def test(self,x_images,model_path):\n",
    "        out_puts = self.cnn_architecture()\n",
    "        predict = tf.nn.softmax(out_puts)\n",
    "        probability = tf.reduce_max(predict, reduction_indices=[1])\n",
    "        predict = tf.argmax(predict, axis=1)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess, model_path)\n",
    "            preds, probs = sess.run([predict, probability], feed_dict={self.x_place: x_images, self.keep_place: 1.0})\n",
    "        return preds,probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-92e0e1be237f>:22: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/evan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /Users/evan/MS/Ece697/bishe /1/./Dataset/models/plate/model.ckpt-510\n",
      "no 0.9998592\n",
      "plate 0.9957224\n",
      "plate 0.99516016\n",
      "no 0.9996463\n",
      "plate 0.9942363\n",
      "plate 0.9999827\n",
      "no 0.99657273\n"
     ]
    }
   ],
   "source": [
    "cur_pos = sys.path[0]\n",
    "data_dir = os.path.join(cur_pos, './Dataset/plate_train')\n",
    "test_dir = os.path.join(cur_pos, './Dataset/plate_test')\n",
    "train_model_path = os.path.join(cur_pos, './Dataset/models/plate/model.ckpt')\n",
    "model_path = os.path.join(cur_pos,'./Dataset/models/plate/model.ckpt-510')\n",
    "\n",
    "train_flag = 0 #set flag = 1 to train, other numbers 0 etc. to test\n",
    "net = plate_recognition_cnn_net()\n",
    "\n",
    "if train_flag == 1:\n",
    "    # train\n",
    "    net.train(data_dir,train_model_path)\n",
    "else:\n",
    "    # test\n",
    "    test_X = net.init_testData(test_dir)\n",
    "    preds,probs = net.test(test_X,model_path)\n",
    "    for i in range(len(preds)):\n",
    "        pred = preds[i].astype(int)\n",
    "        prob = probs[i]\n",
    "        if pred == 1:\n",
    "            print('plate',prob)\n",
    "        else:\n",
    "            print('no',prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
